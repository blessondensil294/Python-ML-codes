Data Science Python Codes Cheatsheet

combine = [train_df, test_df]
for dataset in combine:
    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\.', expand=False)

#-------------------------------------------------------------------------------------------------------------------------------------------------
#Normalize or scale data
1) Log normalization for huge variation in data
df['col'] = np.log(df['col'])

2) Standard Normalize Scaling
from sklearn.preprocessing import StandardScale
scaler = StandardScalar
df_scaler = pd.DataFrame(Scaler.fit_transform(df), columns = df.columns)

3)Scale
from sklearn.preprocessing import Scale
X_scale = scale(x)
np.mean(x)
np.std(x)
np.max(x)
np.std(x_scaled)



#Imput missing data
from sklearn.impute import SimpleImputer
imp = SimpleImputer(missing_values='NAN', strategy = 'mean')

imp.fit(X)
X = imp.fit_transform(X)


#Remove Missing data
df.isna().sum()
df.dropna(axis=0)

#Fill NAN
df.fillna(value)

#-------------------------------------------------------------------------------------------------------------------------------------------------
Treating Outliers

Finding Outliers
import seaborn as sns
sns.boxplot(x=boston_df['DIS'])

fig, ax = plt.subplots(figsize=(16,8))
ax.scatter(boston_df['INDUS'], boston_df['TAX'])
ax.set_xlabel('Proportion of non-retail business acres per town')
ax.set_ylabel('Full-value property-tax rate per $10,000')
plt.show()

Remove outlier

def remove_outlier(df_in, col_name):
    q1 = df_in[col_name].quantile(0.25)
    q3 = df_in[col_name].quantile(0.75)
    iqr = q3-q1 #Interquartile range
    fence_low  = q1-1.5*iqr
    fence_high = q3+1.5*iqr
    df_out = df_in.loc[(df_in[col_name] > fence_low) & (df_in[col_name] < fence_high)]
    return df_out

#-------------------------------------------------------------------------------------------------------------------------------------------------
#Encoding the columns

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
df['columns'] = le.fit_transform(df['columns'])

# Import OneHotEncoder
from sklearn.preprocessing import OneHotEncoder

# Create OneHotEncoder: ohe
ohe = OneHotEncoder(categorical_features=categorical_mask, sparse=False)

# Apply OneHotEncoder to categorical columns - output is no longer a dataframe: df_encoded
df_encoded = ohe.fit_transform(df)

pd.get_dummies(df['columns'])

#-------------------------------------------------------------------------------------------------------------------------------------------------
#Split the data to train and test

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 222, stratify=23)

#-------------------------------------------------------------------------------------------------------------------------------------------------
#SMOTE for imbalance data - synthetic memory overfitting technic on the training data only

X = data_final.loc[:, data_final.columns != 'y']
y = data_final.loc[:, data_final.columns == 'y']

from imblearn.over_sampling import SMOTE
os = SMOTE(random_state=0)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)
columns = X_train.columns
os_data_X,os_data_y=os.fit_sample(X_train, y_train)
os_data_X = pd.DataFrame(data=os_data_X,columns=columns )
os_data_y= pd.DataFrame(data=os_data_y,columns=['y'])

# we can Check the numbers of our data
print("length of oversampled data is ",len(os_data_X))
print("Number of no subscription in oversampled data",len(os_data_y[os_data_y['y']==0]))
print("Number of subscription",len(os_data_y[os_data_y['y']==1]))
print("Proportion of no subscription data in oversampled data is ",len(os_data_y[os_data_y['y']==0])/len(os_data_X))
print("Proportion of subscription data in oversampled data is ",len(os_data_y[os_data_y['y']==1])/len(os_data_X))

#-------------------------------------------------------------------------------------------------------------------------------------------------
#Hyperparameter model using GridsearchCV

from sklearn.model_selection import GridSearchCV
param = {'n_neighbour': np.arange(1,50)}

knn = kneighborClassifier()

knn_cv = GridSearch(knn, param_grid, CV=5)

knn_cv.fit(x, y)

knn_cv.best_params_
knn_cv.best_score_
knn_cv.score(x_test, y_test)

#-------------------------------------------------------------------------------------------------------------------------------------------------
#Confusion Matrix
from sklearn.metric import confusion_matrix
confusion_matrix(y_test, y_pred)

#ROC Curve
from sklearn.metrics import roc_curve

##after fitting
y_pred_prob = logreg.predict_prob(x_test)[,:1]

fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)

#Plotting
plt.plot([0,1], [0,1], 'k--')
plt.plot(fpr, tpr, label='Logistic Regression')

#AUC ROC
from sklearn.metric import roc-auc_score

##after fitting
y_pred_prob = logreg.predictprob(x_test)[:,1]
roc_auc_score(y_test, y_pred_prob)



#Accuracy Score
from sklearn.metrics import accuracy_score

#-------------------------------------------------------------------------------------------------------------------------------------------------
#Cross validation Score
To find the 

>>> from sklearn.model_selection import cross_val_score
SEED = 123
>>> clf = svm.SVC(kernel='linear', C=1)
>>> scores = cross_val_score(clf, iris.data, iris.target, cv=5)
>>> scores                                              
array([0.96..., 1.  ..., 0.96..., 0.96..., 1.        ])

>>> print("Accuracy: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2))
Accuracy: 0.98 (+/- 0.03)

>>> from sklearn import metrics
>>> scores = cross_val_score(clf, iris.data, iris.target, cv=5, scoring='f1_macro')
>>> scores                                              
array([0.96..., 1.  ..., 0.96..., 0.96..., 1.        ])