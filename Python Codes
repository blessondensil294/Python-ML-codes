Data Science Python Codes Cheatsheet

#-------------------------------------------------------------------------------------------------------------------------------------------------
#Normalize or scale data
1) Log normalization for huge variation in data
df['col'] = np.log(df['col'])

2) Standard Normalize Scaling
from sklearn.preprocessing import StandardScale
scaler = StandardScalar
df_scaler = pd.DataFrame(Scaler.fit_transform(df), columns = df.columns)

3)Scale
from sklearn.preprocessing import Scale
X_scale = scale(x)
np.mean(x)
np.std(x)
np.max(x)
np.std(x_scaled)


#-------------------------------------------------------------------------------------------------------------------------------------------------
#Imput missing data
from sklearn.impute import SimpleImputer
imp = SimpleImputer(missing_values='NAN', strategy = 'mean')

imp.fit(X)
X = imp.fit_transform(X)

#-------------------------------------------------------------------------------------------------------------------------------------------------
#Encoding the columns

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
df['columns'] = le.fit_transform(df['columns'])

# Import OneHotEncoder
from sklearn.preprocessing import OneHotEncoder

# Create OneHotEncoder: ohe
ohe = OneHotEncoder(categorical_features=categorical_mask, sparse=False)

# Apply OneHotEncoder to categorical columns - output is no longer a dataframe: df_encoded
df_encoded = ohe.fit_transform(df)

pd.get_dummies(df['columns'])

#-------------------------------------------------------------------------------------------------------------------------------------------------
#Split the data to train and test

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 222, stratify=23)

#-------------------------------------------------------------------------------------------------------------------------------------------------
#SMOTE for imbalance data - synthetic memory overfitting technic on the training data only

X = data_final.loc[:, data_final.columns != 'y']
y = data_final.loc[:, data_final.columns == 'y']

from imblearn.over_sampling import SMOTE
os = SMOTE(random_state=0)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)
columns = X_train.columns
os_data_X,os_data_y=os.fit_sample(X_train, y_train)
os_data_X = pd.DataFrame(data=os_data_X,columns=columns )
os_data_y= pd.DataFrame(data=os_data_y,columns=['y'])

# we can Check the numbers of our data
print("length of oversampled data is ",len(os_data_X))
print("Number of no subscription in oversampled data",len(os_data_y[os_data_y['y']==0]))
print("Number of subscription",len(os_data_y[os_data_y['y']==1]))
print("Proportion of no subscription data in oversampled data is ",len(os_data_y[os_data_y['y']==0])/len(os_data_X))
print("Proportion of subscription data in oversampled data is ",len(os_data_y[os_data_y['y']==1])/len(os_data_X))

#-------------------------------------------------------------------------------------------------------------------------------------------------
#Hyperparameter model using GridsearchCV

from sklearn.model_selection import GridSearchCV
param = {'n_neighbour': np.arange(1,50)}

knn = kneighborClassifier()

knn_cv = GridSearch(knn, param_grid, CV=5)

knn_cv.fit(x, y)

knn_cv.best_params_
knn_cv.best_score_
knn_cv.score(x_test, y_test)

#-------------------------------------------------------------------------------------------------------------------------------------------------
#Confusion Matrix
from sklearn.metric import confusion_matrix
confusion_matrix(y_test, y_pred)

#ROC Curve
from sklearn.metrics import roc_curve

##after fitting
y_pred_prob = logreg.predict_prob(x_test)[,:1]

fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)

#Plotting
plt.plot([0,1], [0,1], 'k--')
plt.plot(fpr, tpr, label='Logistic Regression')

#AUC ROC
from sklearn.metric import roc-auc_score

##after fitting
y_pred_prob = logreg.predictprob(x_test)[:,1]
roc_auc_score(y_test, y_pred_prob)


#-------------------------------------------------------------------------------------------------------------------------------------------------
#Accuracy Score
from sklearn.metrics import accuracy_score


#-------------------------------------------------------------------------------------------------------------------------------------------------

#Models
#1) Linear Regression

#Package
from sklearn.linear_model import LinearRegression
lm = LinearRegression(fit_intercept = True)

#Model Fit
model = lm.fit(x_train, y_train)

#Intercept and slope value
intercept = model.intercept
slope = model.coef_[0]

#Predicting the model
y_pred = model.predict(x_test)

#Evaluating the model
#RMSE
from sklearn import metrics
print('RMSE: ', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))

#R2
from sklearn.metrics import r2_score as r2
r2(y_test, y_pred)

#-------------------------------------------------------------------------------------------------------------------------------------------------

2) Logistic Regression

#Package
from sklearn.linear_model import LogisticRegression
from sklearn import metrics

#model
logreg = LogisticRegression(random_state=1)
logreg.fit(X_train, y_train)

#Predicting
y_pred = logreg.predict(X_test)
print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))

#To plot the decision boundary
plot_labeled_decision_regions(X_test, y_test, logreg)

#-------------------------------------------------------------------------------------------------------------------------------------------------

3) Support Vector Machine

#Linear SVC
#Package
from sklearn.svm import LinearSVC
svm = LinearSVC()

#Model 
model = svm.fit(x_train, y_train)
model.score(x_test, y_test)




#SVC

#Package
from sklearn.svm import SVC
svm = SVC()

#Hyperparameter tuning
from sklearn.model_selection import GridSearchCV
parameter = {'gamma': [0.00001, 0.0001, 0.001, 0.01, 0.1], 'c': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}
svm_searcher = gridsearchCV(svm, parameters)
svm_searcher.fit(x, y)
svm_searcher.best_params_
svm_searcher.best_score_

svm_searcher.score(x_test, y_test)


#Model 
model = svm.fit(x_train, y_train)
model.score(x_test, y_test)

#Plot the model
plot_classifier(x, y, svm, linear=(11,15,0,6))

#-------------------------------------------------------------------------------------------------------------------------------------------------

#4)Schostic Gradient Decent Model for Logistic and SVM for larger dataset

#model
from sklearn.linear_model import SGDClassifier
logreg = SGDClassifier(loss='log')
linsvm = SGDClassifier(loss='hinge')

#Hyperparameter
model = SGDClassifier(random_state = 0)
parameter = {'alpha':[0.00001, 0.0001, 0.001, 0.01, 0.1, 1], 'loss': ['log', 'hinge'], 'penalty': ['l1', 'l2']}

search = GridSearchCV(model, parameter, cv=10)
search.fit(x_train, y_train)
search.best_params_
search.best_score_
search.score(x_test, y_test)

#-------------------------------------------------------------------------------------------------------------------------------------------------
#5) Decision Tree Classifier
#import the model
from sklearn.tree import DecisionTreeClassifier
DT = DecisionTreeClassifier(criterion='gini', max_depth=2, random_state=1) ## criterion='entropy'

# Define params_dt
params_dt = {
             'max_depth': [2, 3, 4],
             'min_samples_leaf': [0.12, 0.14, 0.16, 0.18]
            }
# Import GridSearchCV
from sklearn.model_selection import GridSearchCV

# Instantiate grid_dt
grid_dt = GridSearchCV(estimator=dt, param_grid=params_dt, scoring='roc_auc', cv=5, n_jobs=-1)

 # Import roc_auc_score from sklearn.metrics 
from sklearn.metrics import roc_auc_score

# Extract the best estimator
best_model = grid_dt.best_estimator_

# Predict the test set probabilities of the positive class
y_pred_proba = best_model.predict_proba(X_test)[:,1]

# Compute test_roc_auc
test_roc_auc = roc_auc_score(y_test, y_pred_proba)

# Print test_roc_auc
print('Test set ROC AUC score: {:.3f}'.format(test_roc_auc))

#Fitting the model
dt.fit(x_test, y_test)

#Predicting the model
y_pred = dt.predict(x_test)	

#Evaluate the test set accuracy
accuracy_score(y_test, y_pred)
print("Test set accuracy: {:.2f}".format(acc))

#To plot the decision boundary
plot_labeled_decision_regions(X_test, y_test, dt)

#Decision Tree Regression
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error as MSE

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 222, stratify=23)

from sklearn.model_selection import cross_val_score
SEED = 123

dt = DecisionTreeRegressor(max_depth=4, min_samples_leaf=0.1, random_state=SEED)
#evaluate the list of MSE obtained by 10-fold CV
#set the n_jobs =-1 to exploit all the CPU cores in computation
MSE_CV = - cross_val_score(dt, x_train, y_train, cv=10, scoring='neg_mean_squared_error', n_jobs=-1)

#Fitting the model
dt.fit(x_test, y_test)

#Predicting the model
y_pred = dt.predict(x_test)	

#CV MSE
print('CV MSE: ' MSE_CV.mean())

#Training set MSE
print('Train MSE', MSE(y_train, y_pred))

#Tesst set MSE
print('Test MSE', MSE(y_test, y_pred))

#Evaluating the model
#RMSE
from sklearn import metrics
print('RMSE: ', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))

#-------------------------------------------------------------------------------------------------------------------------------------------------
6) Baggin Classifier

# Import DecisionTreeClassifier
from sklearn.tree import DecisionTreeClassifier

# Import BaggingClassifier
from sklearn.ensemble import BaggingClassifier

# Instantiate dt
dt = DecisionTreeClassifier(random_state=1)

# Instantiate bc
bc = BaggingClassifier(base_estimator=dt, n_estimators=50, oob_score = True, random_state=1)

# Fit bc to the training set
bc.fit(X_train, y_train)

# Predict test set labels
y_pred = bc.predict(X_test)

# Evaluate test set accuracy
acc_test = accuracy_score(y_test, y_pred)

# Evaluate OOB accuracy
acc_oob = bc.oob_score_

# Print acc_test and acc_oob
print('Test set accuracy: {:.3f}, OOB accuracy: {:.3f}'.format(acc_test, acc_oob))

#-------------------------------------------------------------------------------------------------------------------------------------------------
7) Random Forest

#classifire
# Import RandomForestRegressor
from sklearn.ensemble import RandomForestClassifier

#Regression
# Import RandomForestRegressor
from sklearn.ensemble import RandomForestRegressor

# Instantiate rf
rf = RandomForestRegressor(n_estimators=25, random_state=2)

# Define the dictionary 'params_rf'
params_rf = {
             'n_estimators': [100, 350, 500],
             'max_features': ['log2', 'auto', 'sqrt'],
             'min_samples_leaf': [2, 10, 30], 
             }

# Import GridSearchCV
from sklearn.model_selection import  GridSearchCV

# Instantiate grid_rf
grid_rf = GridSearchCV(estimator=rf,
                       param_grid=params_rf,
                       scoring='neg_mean_squared_error',
                       cv=3,
                       verbose=1,
                       n_jobs=-1)

# Extract the best estimator
best_model = grid_rf.best_estimator_

# Predict test set labels
y_pred = best_model.predict(X_test)
					   
# Fit rf to the training set            
rf.fit(X_train, y_train)   

# Import mean_squared_error as MSE
from sklearn.metrics import mean_squared_error as MSE

# Predict the test set labels
y_pred = rf.predict(X_test)

# Evaluate the test set RMSE
rmse_test = MSE(y_test, y_pred)**(1/2)

# Print rmse_test
print('Test set RMSE of rf: {:.2f}'.format(rmse_test))

# Create a pd.Series of features importances
importances = pd.Series(data=rf.feature_importances_, index= X_train.columns)

# Sort importances
importances_sorted = importances.sort_values()

# Draw a horizontal barplot of importances_sorted
importances_sorted.plot(kind='barh', color='lightgreen')
plt.title('Features Importances')
plt.show()

#-------------------------------------------------------------------------------------------------------------------------------------------------
8) AdaBoost

#Classifier
# Import DecisionTreeClassifier
from sklearn.tree import DecisionTreeClassifier

# Import AdaBoostClassifier
from sklearn.ensemble import AdaBoostClassifier

# Instantiate dt
dt = DecisionTreeClassifier(max_depth=2, random_state=1)

# Instantiate ada
ada = AdaBoostClassifier(base_estimator=dt, n_estimators=180, random_state=1)

# Fit ada to the training set
ada.fit(X_train, y_train)

# Compute the probabilities of obtaining the positive class
y_pred_proba = ada.predict_proba(X_test)[:,1]

# Import roc_auc_score
from sklearn.metrics import roc_auc_score

# Evaluate test-set roc_auc_score
ada_roc_auc = roc_auc_score(y_test, y_pred_proba)

# Print roc_auc_score
print('ROC AUC score: {:.2f}'.format(ada_roc_auc))

#Regression
# Import AdaBoostRegressor
from sklearn.ensemble import AdaBoostRegressor

#-------------------------------------------------------------------------------------------------------------------------------------------------
9) Gradient Boosting

# Import GradientBoostingRegressor
from sklearn.ensemble import GradientBoostingRegressor

# Instantiate gb
gb = GradientBoostingRegressor(max_depth=4, n_estimators=200, random_state=2)

# Fit gb to the training set
gb.fit(X_train, y_train)

# Predict test set labels
y_pred = gb.predict(X_test)

# Import mean_squared_error as MSE
from sklearn.metrics import mean_squared_error as MSE

# Compute MSE
mse_test = MSE(y_test, y_pred)

# Compute RMSE
rmse_test = mse_test**(1/2)

# Print RMSE
print('Test set RMSE of gb: {:.3f}'.format(rmse_test))

#-------------------------------------------------------------------------------------------------------------------------------------------------
10) Stochastic Gradient Boosting

# Import GradientBoostingRegressor
from sklearn.ensemble import GradientBoostingRegressor

# Instantiate sgbr
sgbr = GradientBoostingRegressor(max_depth=4, subsample=0.9, max_features=0.75, n_estimators=200, random_state=2)

# Fit sgbr to the training set
sgbr.fit(X_train, y_train)

# Predict test set labels
y_pred = sgbr.predict(X_test)

# Import mean_squared_error as MSE
from sklearn.metrics import mean_squared_error as MSE

# Compute test set MSE
mse_test = MSE(y_test, y_pred)

# Compute test set RMSE
rmse_test = mse_test**(1/2)

# Print rmse_test
print('Test set RMSE of sgbr: {:.3f}'.format(rmse_test))

#-------------------------------------------------------------------------------------------------------------------------------------------------
10) XGBoost

#XGBOOST Classification

#import xgboost
import xgboost as xgb

# Create arrays for the features and the target: X, y
X, y = churn_data.iloc[:,:-1], churn_data.iloc[:,-1]

# Create the training and test sets
X_train,X_test,y_train,y_test= train_test_split(X, y, test_size=0.2, random_state=123)

# Instantiate the XGBClassifier: xg_cl
xg_cl = xgb.XGBClassifier(objective='binary:logistic', n_estimators=10, seed=123)

# Fit the classifier to the training set
xg_cl.fit(X_train,y_train)

# Predict the labels of the test set: preds
preds = xg_cl.predict(X_test)

# Compute the accuracy: accuracy
accuracy = float(np.sum(preds==y_test))/y_test.shape[0]
print("accuracy: %f" % (accuracy))

# Create the DMatrix: churn_dmatrix - 3 Crfoss Fold validation
churn_dmatrix = xgb.DMatrix(data=X, label=y)

# Create the parameter dictionary: params
params = {"objective":"reg:logistic", "max_depth":3}

# Perform cross-validation: cv_results
cv_results = xgb.cv(dtrain=churn_dmatrix, params=params, nfold=3, num_boost_round=5, metrics="error", as_pandas=True, seed=123)

# Print cv_results
print(cv_results)

# Print the accuracy
print(((1-cv_results["test-error-mean"]).iloc[-1]))

# Perform cross_validation: cv_results
cv_results = xgb.cv(dtrain=churn_dmatrix, params=params, nfold=3, num_boost_round=5, metrics="auc", as_pandas=True, seed=123)

# Print cv_results
print(cv_results)

# Print the AUC
print((cv_results["test-auc-mean"]).iloc[-1])

#XGBOOST Regression

'''
Loss function
reg:linear
reg:logistic
binary:logistic

Parameters
1) Learning rate: learning rate/eta - learning how fast the model fits the residual error using base learniners or weak learners
2) gamma: min loss reduction to create new tree split
3) lambda: l2 reg on leaf wieght
4) alpha: L1 reg on leaf weights
5) max_depth: max depth per tree
6) subsample: % samples used per tree - between 0-1. Low - underfittin, high - underfitting
7) colsample_bytree: % features used per tree
8) noofestimatore - tree size
'''

# Create the training and test sets
X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.2, random_state=123)

# Instantiate the XGBRegressor: xg_reg
xg_reg = xgb.XGBRegressor(objective="reg:linear", n_estimators=10, seed=123)

# Fit the regressor to the training set
xg_reg.fit(X_train, y_train)

# Predict the labels of the test set: preds
preds = xg_reg.predict(X_test)

# Compute the rmse: rmse
rmse = np.sqrt(mean_squared_error(y_test, preds))
print("RMSE: %f" % (rmse))


#Linear Base Model
# Convert the training and testing sets into DMatrixes: DM_train, DM_test
DM_train = xgb.DMatrix(data=X_train, label=y_train)
DM_test =  xgb.DMatrix(data=X_test, label=y_test)

# Create the parameter dictionary: params
params = {"booster":"gblinear", "objective":"reg:linear"}

# Train the model: xg_reg
xg_reg = xgb.train(params = params, dtrain=DM_train, num_boost_round=5)

# Predict the labels of the test set: preds
preds = xg_reg.predict(DM_test)

# Compute and print the RMSE
rmse = np.sqrt(mean_squared_error(y_test,preds))
print("RMSE: %f" % (rmse))


#Evaluate Model Quality

###RMSE
# Create the DMatrix: housing_dmatrix
housing_dmatrix = xgb.DMatrix(data=X,label=y)

# Create the parameter dictionary: params
params = {"objective":"reg:linear", "max_depth":4}

tuned_params = {"objective": "reg:linear", 'colsample_bytree': 0.3, 'learning_rate': 0.1, 'max_depth': 5}


# Perform cross-validation: cv_results
cv_results = xgb.cv(dtrain=housing_dmatrix, params=tuned_params, nfold=4, num_boost_round=200, early_stopping_rounds=10, metrics="rmse", as_pandas=True, seed=123)

# Print cv_results
print(cv_results)

# Extract and print final round boosting round metric
print((cv_results["test-rmse-mean"]).tail(1))

###MAE

# Create the DMatrix: housing_dmatrix
housing_dmatrix = xgb.DMatrix(data=X,label=y)

# Create the parameter dictionary: params
params = {"objective":"reg:linear", "max_depth":4}

# Perform cross-validation: cv_results
cv_results = xgb.cv(dtrain=housing_dmatrix, params=params, nfold=4, num_boost_round=5, metrics="mae", as_pandas=True, seed=123)

# Print cv_results
print(cv_results)

# Extract and print final round boosting round metric
print((cv_results["test-mae-mean"]).tail(1))

###regularization in xgBoost
# Create the DMatrix: housing_dmatrix
housing_dmatrix = xgb.DMatrix(data=X, label=y)

reg_params = [1, 10, 100]

# Create the initial parameter dictionary for varying l2 strength: params
params = {"objective":"reg:linear","max_depth":3}

# Create an empty list for storing rmses as a function of l2 complexity
rmses_l2 = []

# Iterate over reg_params
for reg in reg_params:

    # Update l2 strength
    params["lambda"] = reg
    
    # Pass this updated param dictionary into cv
    cv_results_rmse = xgb.cv(dtrain=housing_dmatrix, params=params, nfold=2, num_boost_round=5, metrics="rmse", as_pandas=True, seed=123)
    
    # Append best rmse (final round) to rmses_l2
    rmses_l2.append(cv_results_rmse["test-rmse-mean"].tail(1).values[0])

# Look at best rmse per l2 param
print("Best rmse as a function of l2:")
print(pd.DataFrame(list(zip(reg_params, rmses_l2)), columns=["l2","rmse"]))

##Plotting the xgBoost Graphh
# Create the DMatrix: housing_dmatrix
housing_dmatrix = xgb.DMatrix(data=X, label=y)

# Create the parameter dictionary: params
params = {"objective":"reg:linear", "max_depth":2}

# Train the model: xg_reg
xg_reg = xgb.train(params=params, dtrain=housing_dmatrix, num_boost_round=10)

# Plot the first tree
xgb.plot_tree(xg_reg, num_trees=0)
plt.show()

# Plot the fifth tree
xgb.plot_tree(xg_reg, num_trees=4)
plt.show()

# Plot the last tree sideways
xgb.plot_tree(xg_reg, num_trees=9, rankdir='LR')
plt.show()

##plotting the important feature_importances_# Create the DMatrix: housing_dmatrix
housing_dmatrix = xgb.DMatrix(data=X, label=y)

# Create the parameter dictionary: params
params = {"objective":"reg:linear", "max_depth":4}

# Train the model: xg_reg
xg_reg = xgb.train(params=params, dtrain=housing_dmatrix, num_boost_round=10)

# Plot the feature importances
xgb.plot_importance(xg_reg)
plt.show()

##Gridsearch to hyperparameter the value
from sklearn.model_selection import GridSearchCV

gbm_param_grid = {'learning_rate': [0.01,0.1,0.5,0.9], 'n_estimators': [200], 'subsample': [0.3, 0.5, 0.9]}
gbm_param_grid = {'colsample_bytree': [0.3, 0.7], 'n_estimators': [50], 'max_depth': [2, 5]}

gbm = xgb.XGBRegressor()
grid_mse = GridSearchCV(estimator=gbm, param_grid=gbm_param_grid, scoring='neg_mean_squared_error', cv=4, verbose=1)
grid_mse.fit(X, y)

print("Best parameters found: ",grid_mse.best_params_)

In [13]: print("Lowest RMSE found: ", np.sqrt(np.abs(grid_mse.best_score_)))
Lowest RMSE found:  28530.1829341

#------------------------------------------------------------------------------------------------------------------------
SPARK

SPARKCONTEXT
main entry point for Spark functionality

from PySpark import SparkContext as sc

##Pyspark SQL
# Import SparkSession from pyspark.sql
from pyspark.sql import SparkSession

# Create my_spark
my_spark = SparkSession.builder.getOrCreate()

# Print my_spark
print(my_spark)

# Print the tables in the catalog
print(spark.catalog.listTables())

# Don't change this query
query = "FROM flights SELECT * LIMIT 10"

# Get the first 10 rows of flights
flights10 = spark.sql(query)

# Show the results
flights10.show()

# Don't change this query
query = "SELECT origin, dest, COUNT(*) as N FROM flights GROUP BY origin, dest"

# Run the query
flight_counts = spark.sql(query)

# Convert the results to a pandas DataFrame
pd_counts = flight_counts.toPandas()

# Print the head of pd_counts
print(pd_counts.head())

# Create pd_temp
pd_temp = pd.DataFrame(np.random.random(10))

# Create spark_temp from pd_temp
spark_temp = spark.createDataFrame(pd_temp)

# Examine the tables in the catalog
print(spark.catalog.listTables())

# Add spark_temp to the catalog
spark_temp.createOrReplaceTempView("temp")

# Examine the tables in the catalog again
print(spark.catalog.listTables())

# Don't change this file path
file_path = "/usr/local/share/datasets/airports.csv"

# Read in the airports data
airports = spark.read.csv(file_path, header=True)

# Show the data
airports.show()

# Create the DataFrame flights
flights = spark.table("flights")

# Show the head
print(flights.show())

# Add duration_hrs
flights = flights.withColumn("duration_hrs", flights.air_time/60)

# Filter flights with a SQL string
long_flights1 = flights.filter("distance > 1000")

# Filter flights with a boolean column
long_flights2 = flights.filter(flights.distance > 1000)

# Examine the data to check they're equal
print(long_flights1.show())
print(long_flights2.show())

# Select the first set of columns
selected1 = flights.select("tailnum", "origin", "dest")

# Select the second set of columns
temp = flights.select(flights.origin, flights.dest, flights.carrier)

# Define first filter
filterA = flights.origin == "SEA"

# Define second filter
filterB = flights.dest == "PDX"

# Filter the data, first by filterA then by filterB
selected2 = temp.filter(filterA).filter(filterB)

# Define avg_speed
avg_speed = (flights.distance/(flights.air_time/60)).alias("avg_speed")

# Select the correct columns
speed1 = flights.select("origin", "dest", "tailnum", avg_speed)

# Create the same table using a SQL expression
speed2 = flights.selectExpr("origin", "dest", "tailnum", "distance/(air_time/60) as avg_speed")

# Find the shortest flight from PDX in terms of distance
flights.filter(flights.origin == "PDX").groupBy().min("distance").show()

# Find the longest flight from SEA in terms of duration
flights.filter(flights.origin == "SEA").groupBy().max("air_time").show()

# Average duration of Delta flights
flights.filter(flights.carrier == "DL").filter(flights.origin == "SEA").groupBy().avg("air_time").show()

# Total hours in the air
flights.withColumn("duration_hrs", flights.air_time/60).groupBy().sum("duration_hrs").show()
